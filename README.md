# Propaganda Detection and Technique Classification in Text

This project explores binary and multi-class classification of propaganda in text using machine learning and deep learning. Models were tested on annotated datasets from the Propaganda Techniques Corpus.

## ğŸ¯ Objectives

- Detect whether a sentence contains propaganda (binary)
- Classify the technique used (multi-class: 8 propaganda types)

## ğŸ“¦ Datasets

- Source: [Propaganda Techniques Corpus](https://propaganda.qcri.org/semeval2020-task11/)
- Format: TSV files with sentence and label pairs
- Classes include: loaded language, flag waving, repetition, doubt, causal simplification, and more

## ğŸ§  Methods

### Task 1: Binary Classification (Propaganda vs Not)
- **Naive Bayes with TF-IDF**
- **Logistic Regression with TF-IDF**
- Feature extraction: TF-IDF (unigramâ€“trigram)
- Preprocessing: custom spaCy pipeline + SMOTE for imbalance

### Task 2: Multi-Class Technique Classification
- **Multinomial Logistic Regression** with:
  - Word2Vec
  - TF-IDF
  - Combined Word2Vec + TF-IDF
- **LSTM** with Word2Vec embeddings
- Preprocessing: spaCy-based POS + NER tagging

## âš™ï¸ Preprocessing Pipeline

- Lowercasing, stopword removal
- POS tagging and entity recognition
- Custom transformer pipelines (Scikit-learn compatible)
- Word embeddings (Word2Vec trained from scratch)

## ğŸ“Š Model Performance

| Task | Model | Test Accuracy |
|------|-------|----------------|
| Task 1 | Logistic Regression | **69%** |
| Task 1 | Naive Bayes | 65% |
| Task 2 | Word2Vec + TF-IDF | **47%** |
| Task 2 | LSTM + Word2Vec | 40% |

## ğŸ“ Project Structure

â”œâ”€â”€ report.pdf # Full report with results â”œâ”€â”€ code.pdf # All code used â”œâ”€â”€ predictions.csv # Model outputs â”œâ”€â”€ README.md

markdown
Copy code

## ğŸ“š Libraries Used

- scikit-learn
- imbalanced-learn (SMOTE)
- spaCy, NLTK
- Gensim (Word2Vec)
- TensorFlow/Keras (LSTM)

## ğŸš€ Future Work

- BERT-based classification
- Better class balancing for rare techniques
- Ensemble model experiments
